{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TextAnalysis as TA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = \"\"\"The paper commemorates the 50th anniversary of Stephen Hawking's groundbreaking discovery of black holes emitting thermal radiation, known as Hawking radiation. The authors use dimensional analysis to derive the Hawking temperature, a fundamental concept in modern astrophysics. They demonstrate that black holes have an absolute temperature, TH, which depends inversely on their mass, MBH. The authors also explore the physical implications of Hawking's discovery, including the evaporation of black holes and their entropy.\n",
    "\n",
    "The paper begins by introducing the concept of dimensional analysis, a tool used to study physical quantities with different dimensions. The authors then derive the Hawking temperature using dimensional analysis, starting from the assumption that a static black hole is characterized by its mass. They introduce the standard gravitational parameter, Gm, which is essential to the derivation.\n",
    "\n",
    "The authors then discuss the physical meaning of Hawking's discovery, highlighting the implications of black holes having an absolute temperature. They also explore the concept of entropy, which is proportional to the area of the event horizon. The paper concludes by discussing the challenges of detecting Hawking radiation and the potential applications of analogue gravity, a field that aims to create physical systems that mimic the behavior of gravitational phenomena.\n",
    "\n",
    "Throughout the paper, the authors use a range of technical terms, including dimensional analysis, Hawking radiation, entropy, and analogue gravity. They also provide a detailed derivation of the Hawking temperature, using mathematical equations and formulas. The paper is written in a clear and concise style, making it accessible to readers with a background in astrophysics and physics.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('derive', 'hawking', 'temperature'), 2),\n",
       " (('black', 'holes', 'absolute'), 2),\n",
       " (('holes', 'absolute', 'temperature'), 2),\n",
       " (('commemorates', 'anniversary', 'stephen'), 1),\n",
       " (('anniversary', 'stephen', 'hawking'), 1),\n",
       " (('stephen', 'hawking', 'groundbreaking'), 1),\n",
       " (('hawking', 'groundbreaking', 'discovery'), 1),\n",
       " (('groundbreaking', 'discovery', 'black'), 1),\n",
       " (('discovery', 'black', 'holes'), 1),\n",
       " (('black', 'holes', 'emitting'), 1)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TA.toptrigrams(summary, \"stopwords.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.5333333333333333, 'rouge2': 0.21428571428571427, 'rougeL': 0.4666666666666666, 'rougeLsum': 0.4666666666666666, 'bertscore_precision': 0.8919382095336914, 'bertscore_recall': 0.8505531549453735, 'bertscore_f1': 0.8707542419433594, 'weighted_score': 0.5399683634440104}\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, List\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from rouge_score import rouge_scorer\n",
    "from bert_score import BERTScorer\n",
    "import torch\n",
    "import spacy\n",
    "\n",
    "class ScientificMetricsEvaluator:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize scientific metrics\"\"\"\n",
    "        # Load general scientific language model\n",
    "        self.nlp = spacy.load('en_core_web_sm')\n",
    "        \n",
    "        # Initialize ROUGE\n",
    "        self.rouge_scorer = rouge_scorer.RougeScorer(\n",
    "            ['rouge1', 'rouge2', 'rougeL', 'rougeLsum'],\n",
    "            use_stemmer=True\n",
    "        )\n",
    "        \n",
    "        # Initialize BERTScore with scientific BERT\n",
    "        self.bert_scorer = BERTScorer(\n",
    "            model_type=\"adsabs/astroBERT\",\n",
    "            num_layers=9,\n",
    "            batch_size=32,\n",
    "            nthreads=4,\n",
    "            all_layers=False,\n",
    "            idf=False,\n",
    "            lang='en',\n",
    "            rescale_with_baseline=False\n",
    "        )\n",
    "        \n",
    "\n",
    "    def _preprocess_text(self, text: str) -> str:\n",
    "        \"\"\"Preprocess text while preserving scientific notation and equations\"\"\"\n",
    "        # Basic cleaning\n",
    "        text = text.strip()\n",
    "        \n",
    "        # Handle equations and mathematical expressions\n",
    "        equation_markers = ['$', '\\\\[', '\\\\]', '\\\\(', '\\\\)']\n",
    "        for marker in equation_markers:\n",
    "            text = text.replace(marker, f\" {marker} \")\n",
    "            \n",
    "        return ' '.join(text.split())\n",
    "\n",
    "    def calculate_rouge(self, reference: str, candidate: str) -> Dict[str, float]:\n",
    "        \"\"\"Calculate ROUGE scores\"\"\"\n",
    "        # Preprocess text\n",
    "        reference = self._preprocess_text(reference)\n",
    "        candidate = self._preprocess_text(candidate)\n",
    "        \n",
    "        # Calculate ROUGE scores\n",
    "        scores = self.rouge_scorer.score(reference, candidate)\n",
    "        \n",
    "        # Extract f-measures\n",
    "        return {\n",
    "            'rouge1': scores['rouge1'].fmeasure,\n",
    "            'rouge2': scores['rouge2'].fmeasure,\n",
    "            'rougeL': scores['rougeL'].fmeasure,\n",
    "            'rougeLsum': scores['rougeLsum'].fmeasure\n",
    "        }\n",
    "\n",
    "    def calculate_bertscore(self, reference: str, candidate: str) -> Dict[str, float]:\n",
    "        \"\"\"Calculate BERTScore\"\"\"\n",
    "        # Calculate base BERTScore\n",
    "        P, R, F1 = self.bert_scorer.score([candidate], [reference])\n",
    "        \n",
    "        return {\n",
    "            'precision': float(P[0]),\n",
    "            'recall': float(R[0]),\n",
    "            'f1': float(F1[0])\n",
    "        }\n",
    "\n",
    "    def evaluate_summary(self, reference: str, candidate: str) -> Dict[str, float]:\n",
    "        \"\"\"Calculate all metrics and combine them\"\"\"\n",
    "        # Calculate individual metrics\n",
    "        rouge_scores = self.calculate_rouge(reference, candidate)\n",
    "        bert_scores = self.calculate_bertscore(reference, candidate)\n",
    "        \n",
    "        # Combine scores\n",
    "        final_scores = {\n",
    "            'rouge1': rouge_scores['rouge1'],\n",
    "            'rouge2': rouge_scores['rouge2'],\n",
    "            'rougeL': rouge_scores['rougeL'],\n",
    "            'rougeLsum': rouge_scores['rougeLsum'],\n",
    "            'bertscore_precision': bert_scores['precision'],\n",
    "            'bertscore_recall': bert_scores['recall'],\n",
    "            'bertscore_f1': bert_scores['f1'],\n",
    "        }\n",
    "        \n",
    "        # Calculate weighted final score\n",
    "        weights = {\n",
    "            'rouge2': 0.35,\n",
    "            'rougeL': 0.25,\n",
    "            'bertscore_f1': 0.4,\n",
    "        }\n",
    "        \n",
    "        final_scores['weighted_score'] = sum(\n",
    "            final_scores[metric] * weight\n",
    "            for metric, weight in weights.items()\n",
    "        )\n",
    "        \n",
    "        return final_scores\n",
    "\n",
    "def evaluate_scientific_summary(reference_text: str, summary_text: str) -> Dict[str, float]:\n",
    "    \"\"\"Convenience function for evaluating scientific summaries\"\"\"\n",
    "    evaluator = ScientificMetricsEvaluator()\n",
    "    return evaluator.evaluate_summary(reference_text, summary_text)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    reference = \"\"\"\n",
    "    The study observed gravitational waves from a binary black hole merger.\n",
    "    The signal was detected using laser interferometry.\n",
    "    \"\"\"\n",
    "    \n",
    "    candidate = \"\"\"\n",
    "    Gravitational waves were detected from merging black holes using\n",
    "    laser interferometer measurements.\n",
    "    \"\"\"\n",
    "    \n",
    "    scores = evaluate_scientific_summary(reference, candidate)\n",
    "    print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
