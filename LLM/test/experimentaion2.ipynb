{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForMaskedLM\n",
    "from sentence_transformers import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From üëâv4.50üëà onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
     ]
    }
   ],
   "source": [
    "# model_name = \"nasa-impact/bert-e-base-mlm\"\n",
    "# model = AutoModelForMaskedLM.from_pretrained(model_name)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model.save_pretrained(\"./bert\")\n",
    "# tokenizer.save_pretrained(\"./bert\")\n",
    "\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"./bert\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./bert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = \"\"\"This year marks half a century since Stephen Hawking made his greatest scientific discovery by theoretically proving that ‚Äúblack holes ain‚Äôt so black‚Äù, as they behave like hot bodies with an absolute temperature that depends inversely on their mass. This discovery is expressed by a simple and elegant equation known as the Hawking temperature. The best way to commemorate this great scientific event is by bringing it to a wide audience. The simplest and most transparent and intuitive tool to achieve this goal is dimensional analysis. The objective of this work is to use this tool to derive the Hawking equation, reveal its meaning, and explore its main physical consequences\"\"\"\n",
    "\n",
    "summary = \"\"\"In this paper, the authors commemorate the half-century anniversary of Stephen Hawking\\'s discovery that \"black holes ain\\'t so black\" by describing its temperature with an absolute temperature proportional to its mass. They use a technique called dimensional analysis to derive the \"Hawking equation\" and explore its possible consequences. The authors acknowledge that the scientific value of this discovery remains largely unexplored, and they outline their plan to make it accessible to a wide audience. In particular, they focus on the \"dimensional analysis\" part of the task, which will be useful to gifted high school students, physics teachers, scientists and engineers, and\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = summary.lower().strip()\n",
    "document = document.lower().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_tokens = tokenizer(summary, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "document_tokens = tokenizer(document, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_embedding = model(**summary_tokens)\n",
    "document_embedding = model(**document_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 31116])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_embedding[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 31116])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_embedding[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = document_embedding[0].detach().numpy().reshape(1,-1)\n",
    "b = summary_embedding[0].detach().numpy().reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8463]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "util.cos_sim(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-7250.8081]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "util.euclidean_sim(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., grad_fn=<LinalgVectorNormBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
